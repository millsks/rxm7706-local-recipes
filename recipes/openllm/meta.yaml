{% set name = "openllm" %}
{% set version = "0.5.3" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/openllm-{{ version }}.tar.gz
  sha256: 2b1f8e0e6bfdbe1708676fec97c1c2787db1aae52031b815d8fc0abf85f63d84

build:
  skip: true  # [win or osx]
  skip: true  # [py<38]
  entry_points:
    - openllm = _openllm_tiny._entrypoint:cli
    #- openllm = openllm_cli.entrypoint:cli
    #- openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli
    #- openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli
    #- openllm-get-prompt = openllm_cli.extension.get_prompt:cli
    #- openllm-list-bentos = openllm_cli.extension.list_bentos:cli
    #- openllm-list-models = openllm_cli.extension.list_models:cli
    #- openllm-playground = openllm_cli.extension.playground:cli
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  host:
    - python
    - hatchling ==1.18.0
    - hatch-vcs ==0.3.0
    - hatch-fancy-pypi-readme ==23.1.0
    - pip
  run:
    - python
    - bentoml >=1.2.16
    - transformers >=4.36.0
    - openllm-client >={{ version }}
    - openllm-core >={{ version }}
    - safetensors
# TODO vllm Not Available on Conda-Forge Yet.
    #- vllm >=0.4.2
    - optimum >=1.12.0
    - accelerate
    - ghapi
    - einops
    - sentencepiece
    - scipy
    # pip-tools 7.4.1 has requirement build>=1.0.0, but you have build 0.10.0.
    # openllm 0.5.3 has requirement build[virtualenv]<1, but you have build 1.2.1 # Refer https://github.com/pypa/build/blob/main/pyproject.toml#L77C4-L77C25
    - python-build >=1.0.0
    - virtualenv >=20.0.35
    - click >=8.1.3
    - cuda-python  # [not osx]
    - bitsandbytes <0.42
#  TypeError: You have a type annotation 'dict[str, t.Any]' which makes use of newer typing features than are supported in your version of Python. To handle this error, you should either remove the use of new syntax or install the `eval_type_backport` package.
    - eval_type_backport  # [py<39]
test:
  imports:
    - openllm
  commands:
    #- pip check
# TODO pip check Fauilures
   #  pip-tools 7.4.1 has requirement build>=1.0.0, but you have build 0.10.0.
   #  openllm 0.5.3 requires vllm, which is not installed.
   #  openllm 0.5.3 has requirement build[virtualenv]<1, but you have build 1.2.1.
    - openllm --help
# TODO openllm = openllm_cli.entrypoint:cli is removed
    #- openllm-dive-bentos --help
    #- openllm-get-containerfile --help
    #- openllm-get-prompt --help
    #- openllm-list-bentos --help
    #- openllm-list-models --help
  requires:
    - pip

about:
  summary: 'OpenLLM: Run any open-source LLMs, such as Llama 2, Mistral, as OpenAI compatible API endpoint in the cloud.'
  home: https://github.com/bentoml/OpenLLM
  license: Apache-2.0
  license_file: LICENSE.md

extra:
  recipe-maintainers:
    - rxm7706
    - conda-forge/openllm-client
    - conda-forge/openllm-core
